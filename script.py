import os
import json
from datetime import datetime
from gtts import gTTS
from openai import OpenAI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)
if not client.api_key:
    raise Exception("OPENROUTER_API_KEY not found")

date_str = datetime.utcnow().strftime("%Y-%m-%d")
archive_dir = "archive"
os.makedirs(archive_dir, exist_ok=True)
lesson_dir = f"{archive_dir}/{date_str}"
os.makedirs(lesson_dir, exist_ok=True)
file_path = f"{lesson_dir}/index.html"

if os.path.exists(file_path):
    print("Lesson already exists.")
    exit(0)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  LOAD HISTORY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
history_file = f"{archive_dir}/history.json"
used_phrases = []
if os.path.exists(history_file):
    with open(history_file, "r", encoding="utf-8") as f:
        used_phrases = json.load(f)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GENERATE CONTENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
prompt = f"""
You are a language learning assistant. Generate today's daily English lesson.

Previously used phrases (DO NOT repeat): {used_phrases[-60:]}

Return ONLY a valid JSON object with NO markdown:
{{
  "phrase": "a common English phrase, idiom, or expression",
  "phrase_ar": "ØªØ±Ø¬Ù…Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "pronunciation": "/phonetic pronunciation/",
  "explanation": "Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· ÙˆÙˆØ§Ø¶Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆÙ…ØªÙ‰ ØªÙØ³ØªØ®Ø¯Ù…",
  "usages": [
    "First example sentence using the phrase",
    "Second example sentence",
    "Third example sentence"
  ],
  "joke": {{
    "en": "A short funny joke related to the phrase",
    "ar": "ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ÙƒØªØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
  }},
  "grammar_tip": "Ù†ØµÙŠØ­Ø© Ù‚ÙˆØ§Ø¹Ø¯ÙŠØ© Ù‚ØµÙŠØ±Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø¬Ù…Ù„Ø©",
  "vocabulary": [
    {{"word": "word1", "meaning_ar": "Ø§Ù„Ù…Ø¹Ù†Ù‰", "example": "Example sentence"}},
    {{"word": "word2", "meaning_ar": "Ø§Ù„Ù…Ø¹Ù†Ù‰", "example": "Example sentence"}},
    {{"word": "word3", "meaning_ar": "Ø§Ù„Ù…Ø¹Ù†Ù‰", "example": "Example sentence"}}
  ],
  "quiz": [
    {{
      "question": "Ø³Ø¤Ø§Ù„ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¹Ù† Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¬Ù…Ù„Ø©",
      "options": ["Ø®ÙŠØ§Ø± 1", "Ø®ÙŠØ§Ø± 2", "Ø®ÙŠØ§Ø± 3"],
      "correct": 0
    }},
    {{
      "question": "Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø± Ø¹Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª",
      "options": ["Ø®ÙŠØ§Ø± 1", "Ø®ÙŠØ§Ø± 2", "Ø®ÙŠØ§Ø± 3"],
      "correct": 1
    }}
  ]
}}

Rules:
- Target beginner to intermediate Arabic-speaking learners
- The phrase should be useful in daily life
- Arabic explanations must be clear and simple
- The joke MUST be related to the phrase
- Quiz questions in Arabic, options in Arabic
- Return valid JSON only, no extra text
"""

response = client.chat.completions.create(
    model="openai/gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.8,
)

text = response.choices[0].message.content.strip()
text = text.replace("```json", "").replace("```", "").strip()
data = json.loads(text)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  UPDATE HISTORY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
used_phrases.append(data["phrase"])
with open(history_file, "w", encoding="utf-8") as f:
    json.dump(used_phrases, f, ensure_ascii=False)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GENERATE AUDIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
tts = gTTS(data["phrase"], lang='en')
tts.save(f"{lesson_dir}/phrase.mp3")

for i, vocab in enumerate(data["vocabulary"]):
    tts_w = gTTS(vocab["word"], lang='en')
    tts_w.save(f"{lesson_dir}/word_{i}.mp3")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  BUILD LESSON HTML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Usages HTML
usages_html = ""
for usage in data["usages"]:
    usages_html += f'<div class="usage-item">{usage}</div>\n'

# Vocabulary cards HTML
vocab_html = ""
for i, v in enumerate(data["vocabulary"]):
    vocab_html += f"""
    <div class="vocab-card">
      <button class="vocab-sound-btn" data-audio="word_{i}.mp3">ğŸ”Š</button>
      <div>
        <div class="vocab-word-text">{v['word']}</div>
        <div class="vocab-meaning">{v['meaning_ar']}</div>
        <div class="vocab-example">"{v['example']}"</div>
      </div>
    </div>
    """

# Quiz HTML
quiz_html = ""
for qi, q in enumerate(data["quiz"]):
    opts = ""
    for oi, opt in enumerate(q["options"]):
        opts += f'<button class="quiz-option">{opt}</button>\n'
    quiz_html += f"""
    <div class="quiz-block" data-correct="{q['correct']}" style="margin-bottom:20px;">
      <div class="quiz-question">{qi + 1}. {q['question']}</div>
      <div class="quiz-options">
        {opts}
      </div>
      <div class="quiz-result"></div>
    </div>
    """

# Load template and replace
with open("lesson_template.html", "r", encoding="utf-8") as f:
    template = f.read()

replacements = {
    "{{date}}": date_str,
    "{{phrase}}": data["phrase"],
    "{{phrase_ar}}": data["phrase_ar"],
    "{{pronunciation}}": data["pronunciation"],
    "{{explanation}}": data["explanation"],
    "{{usages}}": usages_html,
    "{{vocab_cards}}": vocab_html,
    "{{joke_en}}": data["joke"]["en"],
    "{{joke_ar}}": data["joke"]["ar"],
    "{{grammar_tip}}": data["grammar_tip"],
    "{{quiz_html}}": quiz_html,
}

lesson_html = template
for key, value in replacements.items():
    lesson_html = lesson_html.replace(key, value)

with open(file_path, "w", encoding="utf-8") as f:
    f.write(lesson_html)
print(f"Lesson created: {file_path}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  UPDATE SEARCH INDEX
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
search_index_file = f"{archive_dir}/lessons-data.json"
search_data = []
if os.path.exists(search_index_file):
    with open(search_index_file, "r", encoding="utf-8") as f:
        search_data = json.load(f)

search_data.append({
    "date": date_str,
    "phrase": data["phrase"],
    "phrase_ar": data["phrase_ar"],
    "vocabulary": [v["word"] for v in data["vocabulary"]]
})

with open(search_index_file, "w", encoding="utf-8") as f:
    json.dump(search_data, f, ensure_ascii=False, indent=2)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  UPDATE INDEX.HTML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
lesson_dirs = sorted(
    [d for d in os.listdir(archive_dir)
     if os.path.isdir(f"{archive_dir}/{d}") and d[0].isdigit()],
    reverse=True
)

links = ""
for d in lesson_dirs[:90]:
    # Load phrase for preview
    preview = ""
    lesson_data_path = f"{archive_dir}/lessons-data.json"
    if os.path.exists(lesson_data_path):
        with open(lesson_data_path, "r", encoding="utf-8") as f:
            all_data = json.load(f)
            match = [x for x in all_data if x["date"] == d]
            if match:
                preview = match[0]["phrase"]

    links += f"""
    <li class="lesson-item" data-date="{d}">
      <a href="archive/{d}/index.html">
        <div>
          <div class="lesson-date">{d}</div>
          <div class="lesson-preview">{preview}</div>
        </div>
        <span class="check-icon">âœ…</span>
      </a>
    </li>
    """

with open("index_template.html", "r", encoding="utf-8") as f:
    index_template = f.read()

index_html = index_template.replace("{{links}}", links)
with open("index.html", "w", encoding="utf-8") as f:
    f.write(index_html)
print("Index updated.")
